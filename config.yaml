batch_size: 8
num_epochs: 20

lr: 0.0001
B1: 0.9
B2: 0.98
ep: 1e-9

seq_len: 500
d_model: 512
N: 6
num_heads: 8
dropout: 0.1
d_ff: 2048

datasource: Angelectronic/IWSLT15_English_Vietnamese
lang_src: en
lang_tgt: vi

model_folder: weights
model_basename: base_transformer
preload: None

tokenizer_file: tokenizer_{0}.json
experiment_name: runs/base_transformer
